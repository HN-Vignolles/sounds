{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Classifier\n",
    "\n",
    "Notebook based/inspired by https://www.tensorflow.org/tutorials/audio/transfer_learning_audio\n",
    "\n",
    "c.f. https://docs.conda.io/en/latest/miniconda.html\n",
    "\n",
    "```bash\n",
    "conda create -n tf python=3.9.12\n",
    "conda activate tf\n",
    "conda install ipykernel\n",
    "pip install tensorflow==2.8.*\n",
    "pip install tensorflow_io==0.25.*\n",
    "conda install -c conda-forge librosa pandas scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import io\n",
    "\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav,sample_rate = tf.audio.decode_wav(file_contents,desired_channels=1)\n",
    "    return convert(wav,sample_rate,16000)\n",
    "\n",
    "def convert_raw_16k_mono(raw,sample_rate):\n",
    "    \"\"\" convert and resample \"\"\"\n",
    "    sample_rate,wav = wavfile.read(io.BytesIO(raw))\n",
    "    wav = librosa.to_mono(wav.T)\n",
    "    wav = tf.expand_dims(wav,axis=1)\n",
    "    return convert(wav,sample_rate,16000)\n",
    "\n",
    "@tf.function\n",
    "def convert(wav,rate_in,rate_out):\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(rate_in,dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav,sample_rate,rate_out)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>Moss-b25d44a9-d884-484c-be08-8e7314615706.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>Moss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>Moss-830c32b6-409a-480e-b9ab-a7fca84c0e87.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>Moss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>Moss-0432cf53-5bb2-4533-bbe6-5513bde2f558.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>Moss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>Moss-d22a6513-1f87-4ea2-881d-c026e594fe57.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>Moss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>Moss-78ffae70-fcfd-4f23-a6f2-539cf4f71255.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>Moss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filename  target category  fold\n",
       "1568  Moss-b25d44a9-d884-484c-be08-8e7314615706.wav      -1     Moss     7\n",
       "1569  Moss-830c32b6-409a-480e-b9ab-a7fca84c0e87.wav      -1     Moss     7\n",
       "1570  Moss-0432cf53-5bb2-4533-bbe6-5513bde2f558.wav      -1     Moss     7\n",
       "1571  Moss-d22a6513-1f87-4ea2-881d-c026e594fe57.wav      -1     Moss     7\n",
       "1572  Moss-78ffae70-fcfd-4f23-a6f2-539cf4f71255.wav      -1     Moss     7"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_data_path = Path('../datasets')\n",
    "data_csv = base_data_path / 'samples.csv'\n",
    "pd_data = pd.read_csv(data_csv)\n",
    "pd_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Moss': 0, 'Jen': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "      <th>category</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/Jen-973efb42-af79-44b9-84f4-225306...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/Jen-0f693473-f947-4459-8c66-96fbd4...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>../datasets/Jen-cc768a6f-e512-4550-b0da-791219...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../datasets/Jen-7e5d37d2-4255-4128-9215-73b056...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../datasets/Jen-43169bf4-dfb4-4e87-8bb8-a11cf5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Jen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  target category  fold\n",
       "2  ../datasets/Jen-973efb42-af79-44b9-84f4-225306...       1      Jen     1\n",
       "4  ../datasets/Jen-0f693473-f947-4459-8c66-96fbd4...       1      Jen     1\n",
       "5  ../datasets/Jen-cc768a6f-e512-4550-b0da-791219...       1      Jen     1\n",
       "6  ../datasets/Jen-7e5d37d2-4255-4128-9215-73b056...       1      Jen     1\n",
       "7  ../datasets/Jen-43169bf4-dfb4-4e87-8bb8-a11cf5...       1      Jen     1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_classes = ['Moss','Jen']\n",
    "map_class_to_id = {k:v for v,k in enumerate(my_classes)}\n",
    "print(map_class_to_id)\n",
    "\n",
    "filtered_pd = pd_data[pd_data.category.isin(my_classes)]\n",
    "\n",
    "class_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\n",
    "# -> class_id: pd of 2,2,...,1 corresponding to \"Jen\",\"Jen\",etc\n",
    "\n",
    "# replace target:-1 with corresponding class id:\n",
    "assigned_pd = filtered_pd.assign(target=class_id)\n",
    "\n",
    "full_path = assigned_pd['filename'].apply(lambda row: str(base_data_path / row))\n",
    "assigned_pd = assigned_pd.assign(filename=full_path)\n",
    "assigned_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold value counts:\n",
      "4    230\n",
      "2    200\n",
      "7    200\n",
      "1    100\n",
      "5    100\n",
      "6    100\n",
      "3     40\n",
      "Name: fold, dtype: int64\n",
      "balance (fold 1): [['Jen', '50'], ['Moss', '50']]\n"
     ]
    }
   ],
   "source": [
    "print(f\"fold value counts:\\n{assigned_pd['fold'].value_counts()}\")\n",
    "\n",
    "balance = assigned_pd[assigned_pd.fold.isin([1])]['category'].value_counts()\n",
    "arr = [s.split() for s in balance.to_string().split('\\n')]\n",
    "print(f'balance (fold 1): {arr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "filenames = assigned_pd['filename']\n",
    "targets = assigned_pd['target']\n",
    "folds = assigned_pd['fold']\n",
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames,targets,folds))\n",
    "print(main_ds.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_wav_for_map(filename,label,fold):\n",
    "    return load_wav_16k_mono(filename),label,fold\n",
    "\n",
    "main_ds = main_ds.map(load_wav_for_map)\n",
    "main_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.shape(embeddings): Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(1024,), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(wav_data, label, fold):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "  print(f'tf.shape(embeddings): {tf.shape(embeddings)}')\n",
    "  # esc50: Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(fold, num_embeddings))\n",
    "\n",
    "# extract embedding\n",
    "main_ds = main_ds.map(extract_embedding).unbatch()\n",
    "main_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_ds = main_ds.cache()\n",
    "train_ds = cached_ds.filter(lambda embedding, label, fold: fold >= 2 and fold <= 6)\n",
    "val_ds = cached_ds.filter(lambda embedding, label, fold: fold == 7)\n",
    "test_ds = cached_ds.filter(lambda embedding, label, fold: fold == 1)\n",
    "\n",
    "# remove the folds column now that it's not needed anymore\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "\n",
    "train_ds = train_ds.map(remove_fold_column)\n",
    "val_ds = val_ds.map(remove_fold_column)\n",
    "test_ds = test_ds.map(remove_fold_column)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 788,482\n",
      "Trainable params: 788,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model = tf.keras.Sequential(name='my_model')\n",
    "my_model.add(tf.keras.layers.Input(shape=(1024),dtype=tf.float32,name='input_embedding'))\n",
    "my_model.add(tf.keras.layers.Dense(512,activation='elu',kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "my_model.add(tf.keras.layers.Dropout(0.5))\n",
    "my_model.add(tf.keras.layers.Dense(512,activation='elu',kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "my_model.add(tf.keras.layers.Dropout(0.5))\n",
    "my_model.add(tf.keras.layers.Dense(len(my_classes)))\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "84/84 [==============================] - 4s 32ms/step - loss: 0.5802 - accuracy: 0.7780 - val_loss: 0.4992 - val_accuracy: 0.8225\n",
      "Epoch 2/20\n",
      "84/84 [==============================] - 2s 25ms/step - loss: 0.4936 - accuracy: 0.8216 - val_loss: 0.5721 - val_accuracy: 0.7875\n",
      "Epoch 3/20\n",
      "84/84 [==============================] - 2s 21ms/step - loss: 0.4499 - accuracy: 0.8362 - val_loss: 0.4969 - val_accuracy: 0.8175\n",
      "Epoch 4/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.4317 - accuracy: 0.8347 - val_loss: 0.4898 - val_accuracy: 0.8288\n",
      "Epoch 5/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.4159 - accuracy: 0.8560 - val_loss: 0.4756 - val_accuracy: 0.8450\n",
      "Epoch 6/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3966 - accuracy: 0.8631 - val_loss: 0.4772 - val_accuracy: 0.8313\n",
      "Epoch 7/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.3906 - accuracy: 0.8537 - val_loss: 0.4845 - val_accuracy: 0.8138\n",
      "Epoch 8/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3796 - accuracy: 0.8675 - val_loss: 0.4683 - val_accuracy: 0.8288\n",
      "Epoch 9/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3702 - accuracy: 0.8683 - val_loss: 0.4846 - val_accuracy: 0.8288\n",
      "Epoch 10/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3796 - accuracy: 0.8690 - val_loss: 0.4741 - val_accuracy: 0.8400\n",
      "Epoch 11/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3553 - accuracy: 0.8810 - val_loss: 0.5115 - val_accuracy: 0.8288\n",
      "Epoch 12/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3493 - accuracy: 0.8769 - val_loss: 0.5499 - val_accuracy: 0.7962\n",
      "Epoch 13/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3622 - accuracy: 0.8735 - val_loss: 0.4801 - val_accuracy: 0.8263\n",
      "Epoch 14/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3402 - accuracy: 0.8757 - val_loss: 0.4812 - val_accuracy: 0.8263\n",
      "Epoch 15/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3448 - accuracy: 0.8791 - val_loss: 0.5006 - val_accuracy: 0.8250\n",
      "Epoch 16/20\n",
      "84/84 [==============================] - 2s 22ms/step - loss: 0.3409 - accuracy: 0.8821 - val_loss: 0.5209 - val_accuracy: 0.8150\n",
      "Epoch 17/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.3386 - accuracy: 0.8780 - val_loss: 0.5231 - val_accuracy: 0.8200\n",
      "Epoch 18/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.3363 - accuracy: 0.8806 - val_loss: 0.5134 - val_accuracy: 0.8175\n",
      "Epoch 19/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.3285 - accuracy: 0.8907 - val_loss: 0.4890 - val_accuracy: 0.8263\n",
      "Epoch 20/20\n",
      "84/84 [==============================] - 2s 23ms/step - loss: 0.3244 - accuracy: 0.8858 - val_loss: 0.4947 - val_accuracy: 0.8225\n"
     ]
    }
   ],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'],\n",
    "                 optimizer='adam')\n",
    "#early_stop = tf.keras.callbacks.EarlyStopping()\n",
    "history = my_model.fit(train_ds,\n",
    "                        epochs=20,\n",
    "                        validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 9ms/step - loss: 0.5341 - accuracy: 0.8000\n",
      "Loss:  0.534130871295929\n",
      "Accuracy:  0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = my_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0523ac5301ecd275eb9e97b1d72e4479446afbac34aae20e7547092e43923f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
